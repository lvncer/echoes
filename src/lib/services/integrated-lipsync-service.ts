import { blendShapeService } from "./blend-shape-service";
import { SpeechSynthesisService } from "./speech-synthesis";
import { AdvancedLipSyncService } from "./advanced-lipsync-service";
import { LipSyncService } from "./lipsync-service";

/**
 * çµ±åˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚µãƒ¼ãƒ“ã‚¹
 * TTSéŸ³å£°ã¨ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã®çµ±åˆåˆ¶å¾¡ã€æ„Ÿæƒ…è¡¨ç¾ã€AIå¿œç­”é€£å‹•
 */
export class IntegratedLipSyncService {
  private speechSynthesis: SpeechSynthesisService;
  private advancedLipSync: AdvancedLipSyncService;
  private basicLipSync: LipSyncService;

  private isActive = false;
  private currentMode: "basic" | "advanced" = "advanced";
  private isAutoMode = true; // AIå¿œç­”æ™‚ã®è‡ªå‹•ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯

  // æ„Ÿæƒ…è¡¨ç¾åˆ¶å¾¡
  private currentEmotion: EmotionType = "neutral";
  private emotionIntensity = 0.5;
  private emotionDuration = 2000; // ms

  // TTSé€£å‹•åˆ¶å¾¡
  private isTTSSpeaking = false;
  private ttsAudioContext: AudioContext | null = null;
  private ttsAnalyser: AnalyserNode | null = null;
  private ttsAnimationFrame: number | null = null;

  constructor() {
    this.speechSynthesis = new SpeechSynthesisService();
    this.advancedLipSync = new AdvancedLipSyncService();
    this.basicLipSync = new LipSyncService();

    this.setupTTSIntegration();
  }

  /**
   * TTSçµ±åˆã®åˆæœŸåŒ–
   */
  private setupTTSIntegration(): void {
    // TTSéŸ³å£°åˆæˆã‚¤ãƒ™ãƒ³ãƒˆã®ç›£è¦–
    this.speechSynthesis.setEventListeners({
      onSpeechStart: () => {
        console.log("TTSéŸ³å£°é–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆå—ä¿¡");
        this.handleTTSSpeechStart();
      },
      onSpeechEnd: () => {
        console.log("TTSéŸ³å£°çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆå—ä¿¡");
        this.handleTTSSpeechEnd();
      },
      onError: (error: string) => {
        console.error("TTSéŸ³å£°ã‚¨ãƒ©ãƒ¼:", error);
        this.handleTTSSpeechEnd();
      },
    });
  }

  /**
   * AIå¿œç­”æ™‚ã®è‡ªå‹•ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹
   */
  async startAIResponseLipSync(
    responseText: string,
    emotion?: EmotionType
  ): Promise<void> {
    if (!this.isAutoMode) return;

    try {
      // æ„Ÿæƒ…è§£æ
      const detectedEmotion = emotion || this.analyzeTextEmotion(responseText);

      // æ„Ÿæƒ…è¡¨ç¾ã‚’é©ç”¨
      await this.applyEmotion(detectedEmotion);

      // TTSéŸ³å£°ã®æº–å‚™
      await this.prepareTTSLipSync();

      // TTSéŸ³å£°é–‹å§‹ï¼ˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã¯è‡ªå‹•ã§é–‹å§‹ã•ã‚Œã‚‹ï¼‰
      const success = this.speechSynthesis.speak(responseText);

      if (success) {
        console.log(
          `AIå¿œç­”ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹: ${responseText.substring(0, 50)}...`
        );
        console.log(`æ¤œå‡ºã•ã‚ŒãŸæ„Ÿæƒ…: ${detectedEmotion}`);

        // éŸ³å£°åˆæˆã®çŠ¶æ…‹ã‚’å®šæœŸçš„ã«ãƒã‚§ãƒƒã‚¯
        this.startSpeechStatusMonitoring();
      } else {
        console.error("éŸ³å£°åˆæˆã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ");
        this.isTTSSpeaking = false;
      }
    } catch (error) {
      console.error("AIå¿œç­”ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹ã‚¨ãƒ©ãƒ¼:", error);
      this.isTTSSpeaking = false;
    }
  }

  /**
   * éŸ³å£°åˆæˆçŠ¶æ…‹ã®ç›£è¦–ã‚’é–‹å§‹
   */
  private startSpeechStatusMonitoring(): void {
    let monitorCount = 0;
    const maxMonitorTime = 30000; // 30ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    const maxChecks = maxMonitorTime / 200;

    const checkStatus = () => {
      monitorCount++;
      const isSpeaking = this.speechSynthesis.isSpeaking();

      if (this.isTTSSpeaking && !isSpeaking) {
        // éŸ³å£°åˆæˆãŒçµ‚äº†ã—ãŸãŒã€å†…éƒ¨çŠ¶æ…‹ãŒã¾ã è©±ã—ä¸­ã®å ´åˆ
        console.log("ğŸ” éŸ³å£°åˆæˆçµ‚äº†ã‚’æ¤œçŸ¥ - çŠ¶æ…‹ã‚’æ›´æ–°");
        this.handleTTSSpeechEnd();
      } else if (this.isTTSSpeaking && monitorCount < maxChecks) {
        // ã¾ã è©±ã—ã¦ã„ã‚‹å ´åˆã¯ç¶™ç¶šç›£è¦–
        setTimeout(checkStatus, 200);
      } else if (monitorCount >= maxChecks) {
        // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ - å¼·åˆ¶çµ‚äº†
        console.warn("âš ï¸ éŸ³å£°åˆæˆç›£è¦–ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ - å¼·åˆ¶çµ‚äº†");
        this.forceStopTTS();
      }
    };

    // 1ç§’å¾Œã‹ã‚‰ç›£è¦–é–‹å§‹
    setTimeout(checkStatus, 1000);
  }

  /**
   * TTSéŸ³å£°ã‚’å¼·åˆ¶åœæ­¢
   */
  private forceStopTTS(): void {
    console.log("ğŸ›‘ TTSéŸ³å£°å¼·åˆ¶åœæ­¢");
    this.isTTSSpeaking = false;
    this.speechSynthesis.stop();
    this.stopTTSAnalysis();
    this.applyEmotion("neutral", 0.3);
  }

  /**
   * ãƒã‚¤ã‚¯å…¥åŠ›ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹
   */
  async startMicrophoneLipSync(stream: MediaStream): Promise<void> {
    try {
      this.isActive = true;

      if (this.currentMode === "advanced") {
        await this.advancedLipSync.startAdvancedLipSync(stream);
      } else {
        await this.basicLipSync.startLipSync(stream);
      }

      console.log(`ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹ (${this.currentMode}ãƒ¢ãƒ¼ãƒ‰)`);
    } catch (error) {
      console.error("ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹ã‚¨ãƒ©ãƒ¼:", error);
      throw error;
    }
  }

  /**
   * ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯åœæ­¢
   */
  stopLipSync(): void {
    this.isActive = false;

    // å„ã‚µãƒ¼ãƒ“ã‚¹ã‚’åœæ­¢
    this.advancedLipSync.stopAdvancedLipSync();
    this.basicLipSync.stopLipSync();
    this.speechSynthesis.stop();

    // TTSè§£æã‚’åœæ­¢
    this.stopTTSAnalysis();

    // è¡¨æƒ…ã‚’ãƒªã‚»ãƒƒãƒˆ
    this.resetExpression();

    console.log("çµ±åˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯åœæ­¢");
  }

  /**
   * TTSéŸ³å£°é–‹å§‹æ™‚ã®å‡¦ç†
   */
  private async handleTTSSpeechStart(): Promise<void> {
    this.isTTSSpeaking = true;
    console.log("TTSéŸ³å£°é–‹å§‹ - ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯é–‹å§‹");

    // TTSéŸ³å£°ã®è§£æã‚’é–‹å§‹
    await this.startTTSAnalysis();
  }

  /**
   * TTSéŸ³å£°çµ‚äº†æ™‚ã®å‡¦ç†
   */
  private handleTTSSpeechEnd(): void {
    console.log("ğŸ”Š TTSéŸ³å£°çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆå—ä¿¡");
    this.isTTSSpeaking = false;

    // TTSè§£æã‚’åœæ­¢
    this.stopTTSAnalysis();

    // è¡¨æƒ…ã‚’å¾ã€…ã«ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã«æˆ»ã™
    setTimeout(() => {
      this.applyEmotion("neutral", 0.3);
    }, 500);

    console.log("âœ… TTSéŸ³å£°çµ‚äº† - çµ±åˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯åœæ­¢å®Œäº†");
  }

  /**
   * TTSéŸ³å£°è§£æã®æº–å‚™
   */
  private async prepareTTSLipSync(): Promise<void> {
    try {
      // Web Audio APIã®åˆæœŸåŒ–
      if (!this.ttsAudioContext) {
        this.ttsAudioContext = new (window.AudioContext ||
          (window as unknown as { webkitAudioContext: typeof AudioContext })
            .webkitAudioContext)();
      }

      if (this.ttsAudioContext.state === "suspended") {
        await this.ttsAudioContext.resume();
      }
    } catch (error) {
      console.error("TTSéŸ³å£°è§£ææº–å‚™ã‚¨ãƒ©ãƒ¼:", error);
    }
  }

  /**
   * TTSéŸ³å£°è§£æé–‹å§‹
   */
  private async startTTSAnalysis(): Promise<void> {
    if (!this.ttsAudioContext) return;

    try {
      // éŸ³å£°å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯åˆ¶é™ãŒã‚ã‚‹ãŸã‚ã€ä»£æ›¿æ‰‹æ³•ã‚’ä½¿ç”¨ï¼‰
      // ã“ã“ã§ã¯éŸ³é‡ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’å®Ÿè£…
      this.startTTSVolumeBasedLipSync();
    } catch (error) {
      console.error("TTSéŸ³å£°è§£æé–‹å§‹ã‚¨ãƒ©ãƒ¼:", error);
    }
  }

  /**
   * TTSéŸ³é‡ãƒ™ãƒ¼ã‚¹ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯
   */
  private startTTSVolumeBasedLipSync(): void {
    let phase = 0;
    const frequency = 0.1; // å£ãƒ‘ã‚¯ã®å‘¨æ³¢æ•°

    const animate = () => {
      if (!this.isTTSSpeaking) return;

      // ç°¡æ˜“çš„ãªå£ãƒ‘ã‚¯ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
      phase += frequency;
      const mouthOpening = (Math.sin(phase) + 1) * 0.3; // 0-0.6ã®ç¯„å›²

      // VRM 1.0å½¢å¼ã®éŸ³ç´ ã‚’ä½¿ç”¨ï¼ˆãƒ‹ã‚³ãƒ‹ç«‹ä½“ã¡ã‚ƒã‚“å¯¾å¿œï¼‰
      const phonemes = ["aa", "ih", "ou", "ee", "oh"]; // VRM 1.0å½¢å¼ã‚’å„ªå…ˆ
      const randomPhoneme =
        phonemes[Math.floor(Math.random() * phonemes.length)];

      // ãƒ–ãƒ¬ãƒ³ãƒ‰ã‚·ã‚§ã‚¤ãƒ—ã‚’é©ç”¨ï¼ˆãƒãƒƒãƒ”ãƒ³ã‚°æ©Ÿèƒ½ã«ã‚ˆã‚Šè‡ªå‹•å¤‰æ›ã•ã‚Œã‚‹ï¼‰
      blendShapeService.setBlendShapeWeight(randomPhoneme, mouthOpening);

      this.ttsAnimationFrame = requestAnimationFrame(animate);
    };

    animate();
  }

  /**
   * TTSè§£æåœæ­¢
   */
  private stopTTSAnalysis(): void {
    if (this.ttsAnimationFrame) {
      cancelAnimationFrame(this.ttsAnimationFrame);
      this.ttsAnimationFrame = null;
    }
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ„Ÿæƒ…ã‚’è§£æ
   */
  private analyzeTextEmotion(text: string): EmotionType {
    // ç°¡æ˜“çš„ãªæ„Ÿæƒ…è§£æï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰
    const emotionKeywords = {
      happy: [
        "å¬‰ã—ã„",
        "æ¥½ã—ã„",
        "è‰¯ã„",
        "ç´ æ™´ã‚‰ã—ã„",
        "æœ€é«˜",
        "ã‚ã‚ŠãŒã¨ã†",
        "ğŸ˜Š",
        "ğŸ˜„",
        "ğŸ‰",
      ],
      sad: [
        "æ‚²ã—ã„",
        "æ®‹å¿µ",
        "å›°ã£ãŸ",
        "ç”³ã—è¨³",
        "ã™ã¿ã¾ã›ã‚“",
        "ğŸ˜¢",
        "ğŸ˜",
        "ğŸ’§",
      ],
      angry: ["æ€’ã‚Š", "è…¹ç«‹ã¤", "ãƒ ã‚«ã¤ã", "è¨±ã›ãªã„", "ğŸ˜ ", "ğŸ˜¡", "ğŸ’¢"],
      surprised: [
        "é©šã",
        "ã³ã£ãã‚Š",
        "ã¾ã•ã‹",
        "ä¿¡ã˜ã‚‰ã‚Œãªã„",
        "ğŸ˜²",
        "ğŸ˜®",
        "â€¼ï¸",
      ],
      neutral: [],
    };

    for (const [emotion, keywords] of Object.entries(emotionKeywords)) {
      if (keywords.some((keyword) => text.includes(keyword))) {
        return emotion as EmotionType;
      }
    }

    return "neutral";
  }

  /**
   * æ„Ÿæƒ…è¡¨ç¾ã‚’é©ç”¨
   */
  private async applyEmotion(
    emotion: EmotionType,
    intensity: number = this.emotionIntensity
  ): Promise<void> {
    this.currentEmotion = emotion;

    // æ„Ÿæƒ…ã«å¯¾å¿œã™ã‚‹ãƒ–ãƒ¬ãƒ³ãƒ‰ã‚·ã‚§ã‚¤ãƒ—ã‚’è¨­å®š
    const emotionBlendShapes = this.getEmotionBlendShapes(emotion, intensity);

    // æ—¢å­˜ã®è¡¨æƒ…ã‚’ãƒªã‚»ãƒƒãƒˆ
    blendShapeService.resetAllBlendShapes();

    // æ–°ã—ã„è¡¨æƒ…ã‚’é©ç”¨
    blendShapeService.setMultipleBlendShapes(emotionBlendShapes);

    console.log(`æ„Ÿæƒ…è¡¨ç¾é©ç”¨: ${emotion} (å¼·åº¦: ${intensity})`);
  }

  /**
   * æ„Ÿæƒ…ã«å¯¾å¿œã™ã‚‹ãƒ–ãƒ¬ãƒ³ãƒ‰ã‚·ã‚§ã‚¤ãƒ—ã‚’å–å¾—
   */
  private getEmotionBlendShapes(
    emotion: EmotionType,
    intensity: number
  ): Record<string, number> {
    const emotionMappings: Record<EmotionType, Record<string, number>> = {
      neutral: {},
      happy: {
        Joy: intensity * 0.8,
        A: intensity * 0.3,
      },
      sad: {
        Sorrow: intensity * 0.7,
        E: intensity * 0.2,
      },
      angry: {
        Angry: intensity * 0.8,
        U: intensity * 0.4,
      },
      surprised: {
        Fun: intensity * 0.9,
        A: intensity * 0.5,
        O: intensity * 0.3,
      },
    };

    return emotionMappings[emotion] || {};
  }

  /**
   * è¡¨æƒ…ã‚’ãƒªã‚»ãƒƒãƒˆ
   */
  private resetExpression(): void {
    blendShapeService.resetAllBlendShapes();
    this.currentEmotion = "neutral";
  }

  // è¨­å®šãƒ¡ã‚½ãƒƒãƒ‰
  public setMode(mode: "basic" | "advanced"): void {
    this.currentMode = mode;
  }

  public setAutoMode(enabled: boolean): void {
    this.isAutoMode = enabled;
  }

  public setEmotionIntensity(intensity: number): void {
    this.emotionIntensity = Math.max(0, Math.min(1, intensity));
  }

  // çŠ¶æ…‹å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰
  public getStatus() {
    return {
      isActive: this.isActive,
      currentMode: this.currentMode,
      isAutoMode: this.isAutoMode,
      currentEmotion: this.currentEmotion,
      isTTSSpeaking: this.isTTSSpeaking,
    };
  }
}

// æ„Ÿæƒ…ã‚¿ã‚¤ãƒ—ã®å®šç¾©
export type EmotionType = "neutral" | "happy" | "sad" | "angry" | "surprised";

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const integratedLipSyncService = new IntegratedLipSyncService();
