/**
 * éŸ³å£°å‡¦ç†ã¨AIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®çµ±åˆã‚µãƒ¼ãƒ“ã‚¹
 * éŸ³å£°å…¥åŠ› â†’ AIå¿œç­” â†’ éŸ³å£°å‡ºåŠ›ã®å®Œå…¨ãªãƒ•ãƒ­ãƒ¼ã‚’ç®¡ç†
 */

import { AudioInputService } from "./audio-input";
import { SpeechRecognitionService } from "./speech-recognition";
import { SpeechSynthesisService } from "./speech-synthesis";
import { integratedLipSyncService } from "./integrated-lipsync-service";
import type {
  AudioConfig,
  AudioError,
  SpeechRecognitionResult,
} from "../types/audio";

export interface AudioChatConfig {
  // éŸ³å£°å…¥åŠ›è¨­å®š
  audioInput: Partial<AudioConfig>;
  // éŸ³å£°èªè­˜è¨­å®š
  speechRecognition: {
    language: string;
    continuous: boolean;
    interimResults: boolean;
  };
  // éŸ³å£°åˆæˆè¨­å®š
  speechSynthesis: {
    voice?: SpeechSynthesisVoice;
    rate: number;
    pitch: number;
    volume: number;
  };
  // AIå¿œç­”è¨­å®š
  aiResponse: {
    provider: "openai" | "gemini";
    model: string;
    maxTokens?: number;
    temperature?: number;
  };
}

export interface AudioChatCallbacks {
  onListeningStart?: () => void;
  onListeningEnd?: () => void;
  onTranscriptReceived?: (transcript: string, isFinal: boolean) => void;
  onAIResponseReceived?: (response: string) => void;
  onSpeechStart?: () => void;
  onSpeechEnd?: () => void;
  onError?: (error: AudioError) => void;
  onStatusChange?: (status: AudioChatStatus) => void;
}

export type AudioChatStatus =
  | "idle"
  | "listening"
  | "processing"
  | "speaking"
  | "error";

export class AudioChatIntegrationService {
  private audioInput: AudioInputService;
  private speechRecognition: SpeechRecognitionService;
  private speechSynthesis: SpeechSynthesisService;
  private config: AudioChatConfig;
  private callbacks: AudioChatCallbacks;
  private status: AudioChatStatus = "idle";
  private isActive = false;
  private lastStatusLogTime = 0;

  constructor(config: AudioChatConfig, callbacks: AudioChatCallbacks = {}) {
    this.config = config;
    this.callbacks = callbacks;

    // ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–ï¼ˆå¼•æ•°ãªã—ã§åˆæœŸåŒ–ï¼‰
    this.audioInput = new AudioInputService();
    this.speechRecognition = new SpeechRecognitionService();
    this.speechSynthesis = new SpeechSynthesisService();

    this.setupEventHandlers();
    this.updateServiceConfigs();
  }

  /**
   * ã‚µãƒ¼ãƒ“ã‚¹è¨­å®šã‚’æ›´æ–°
   */
  private updateServiceConfigs(): void {
    // éŸ³å£°èªè­˜è¨­å®šã‚’æ›´æ–°
    this.speechRecognition.updateConfig({
      language: this.config.speechRecognition.language,
      continuous: this.config.speechRecognition.continuous,
      interimResults: this.config.speechRecognition.interimResults,
      maxAlternatives: 1,
    });

    // éŸ³å£°åˆæˆè¨­å®šã‚’æ›´æ–°
    this.speechSynthesis.updateConfig({
      voice: this.config.speechSynthesis.voice,
      rate: this.config.speechSynthesis.rate,
      pitch: this.config.speechSynthesis.pitch,
      volume: this.config.speechSynthesis.volume,
      language: this.config.speechRecognition.language,
    });
  }

  /**
   * ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®è¨­å®š
   */
  private setupEventHandlers(): void {
    // éŸ³å£°èªè­˜ã‚¤ãƒ™ãƒ³ãƒˆ
    this.speechRecognition.setEventListeners({
      onResult: (result: SpeechRecognitionResult) => {
        this.callbacks.onTranscriptReceived?.(
          result.transcript,
          result.isFinal
        );

        if (result.isFinal && result.transcript.trim()) {
          this.handleFinalTranscript(result.transcript);
        }
      },
      onSpeechStart: () => {
        this.setStatus("listening");
        this.callbacks.onListeningStart?.();
      },
      onSpeechEnd: () => {
        if (this.status === "listening") {
          this.setStatus("idle");
          this.callbacks.onListeningEnd?.();
        }
      },
      onError: (error: string) => {
        this.handleError({
          type: "speech-recognition-failed",
          message: error,
        });
      },
    });

    // éŸ³å£°åˆæˆã‚¤ãƒ™ãƒ³ãƒˆ
    this.speechSynthesis.setEventListeners({
      onSpeechStart: () => {
        this.setStatus("speaking");
        this.callbacks.onSpeechStart?.();
      },
      onSpeechEnd: () => {
        this.setStatus("idle");
        this.callbacks.onSpeechEnd?.();
      },
      onError: (error: string) => {
        this.handleError({
          type: "speech-synthesis-failed",
          message: error,
        });
      },
    });
  }

  /**
   * éŸ³å£°ãƒãƒ£ãƒƒãƒˆé–‹å§‹
   */
  public async startAudioChat(): Promise<boolean> {
    try {
      if (this.isActive) {
        console.warn("éŸ³å£°ãƒãƒ£ãƒƒãƒˆã¯æ—¢ã«é–‹å§‹ã•ã‚Œã¦ã„ã¾ã™");
        return true;
      }

      // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’å–å¾—
      const hasPermission = await this.audioInput.requestMicrophoneAccess(
        this.config.audioInput
      );
      if (!hasPermission) {
        this.handleError({
          type: "permission-denied",
          message: "ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ",
        });
        return false;
      }

      this.isActive = true;
      this.setStatus("idle");
      return true;
    } catch (error) {
      this.handleError({
        type: "initialization-failed",
        message: `éŸ³å£°ãƒãƒ£ãƒƒãƒˆåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error}`,
      });
      return false;
    }
  }

  /**
   * éŸ³å£°ãƒãƒ£ãƒƒãƒˆåœæ­¢
   */
  public stopAudioChat(): void {
    if (!this.isActive) return;

    this.speechRecognition.stop();
    this.speechSynthesis.stop();
    this.audioInput.stopRecording();

    this.isActive = false;
    this.setStatus("idle");
  }

  /**
   * éŸ³å£°å…¥åŠ›é–‹å§‹ï¼ˆãƒ—ãƒƒã‚·ãƒ¥ãƒˆã‚¥ãƒˆãƒ¼ã‚¯ï¼‰
   */
  public startListening(): boolean {
    if (!this.isActive || this.status !== "idle") {
      return false;
    }

    return this.speechRecognition.start();
  }

  /**
   * éŸ³å£°å…¥åŠ›åœæ­¢
   */
  public stopListening(): void {
    if (this.status === "listening") {
      this.speechRecognition.stop();
    }
  }

  /**
   * æœ€çµ‚çš„ãªéŸ³å£°èªè­˜çµæœã®å‡¦ç†
   */
  private async handleFinalTranscript(transcript: string): Promise<void> {
    try {
      console.log(`ğŸ“ éŸ³å£°èªè­˜å®Œäº†: "${transcript}"`);
      this.setStatus("processing");

      // AIå¿œç­”ã‚’å–å¾—
      console.log("ğŸ¤– AIå¿œç­”å–å¾—é–‹å§‹");
      const aiResponse = await this.getAIResponse(transcript);
      console.log(`ğŸ¤– AIå¿œç­”å–å¾—å®Œäº†: "${aiResponse.substring(0, 50)}..."`);
      this.callbacks.onAIResponseReceived?.(aiResponse);

      // éŸ³å£°åˆæˆã§å¿œç­”ã‚’å†ç”Ÿ
      console.log("ğŸ”Š éŸ³å£°åˆæˆé–‹å§‹");
      await this.speakResponse(aiResponse);
      console.log("ğŸ”Š éŸ³å£°åˆæˆå®Œäº† - å‡¦ç†çµ‚äº†");

      // ç¢ºå®Ÿã«ã‚¢ã‚¤ãƒ‰ãƒ«çŠ¶æ…‹ã«æˆ»ã™
      this.setStatus("idle");
    } catch (error) {
      console.error("âŒ AIå¿œç­”å‡¦ç†ã‚¨ãƒ©ãƒ¼:", error);
      this.handleError({
        type: "ai-response-failed",
        message: `AIå¿œç­”ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: ${error}`,
      });
      // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ç¢ºå®Ÿã«ã‚¢ã‚¤ãƒ‰ãƒ«çŠ¶æ…‹ã«æˆ»ã™
      this.setStatus("idle");
    }
  }

  /**
   * AIå¿œç­”ã®å–å¾—
   */
  private async getAIResponse(userMessage: string): Promise<string> {
    // æ—¢å­˜ã®chat APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨äº’æ›æ€§ã®ã‚ã‚‹å½¢å¼ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    const messages = [
      {
        id: `user_${Date.now()}`,
        role: "user" as const,
        content: userMessage,
        timestamp: new Date(),
      },
    ];

    const response = await fetch("/api/chat", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        messages,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(
        `AI API ã‚¨ãƒ©ãƒ¼: ${response.status} - ${
          errorData.error || "Unknown error"
        }`
      );
    }

    const data = await response.json();

    // APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰é©åˆ‡ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
    if (data.message && data.message.content) {
      return data.message.content;
    }

    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return data.response || "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚";
  }

  /**
   * AIå¿œç­”ã®éŸ³å£°åˆæˆ
   */
  private async speakResponse(text: string): Promise<void> {
    try {
      console.log(`ğŸ­ AIå¿œç­”ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é€£å‹•é–‹å§‹: "${text.substring(0, 50)}..."`);

      // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡ã‚µãƒ¼ãƒ“ã‚¹ã§æ„Ÿæƒ…è§£æã¨ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
      if (typeof window !== "undefined") {
        const windowWithController = window as typeof window & {
          __animationController?: {
            analyzeAndPlayEmotionAnimation: (text: string) => void;
          };
        };
        if (windowWithController.__animationController) {
          console.log("ğŸ­ ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ç™ºè¦‹ - æ„Ÿæƒ…è§£æå®Ÿè¡Œ");
          windowWithController.__animationController.analyzeAndPlayEmotionAnimation(
            text
          );
          console.log("ğŸ­ æ„Ÿæƒ…è§£æãƒ»ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå®Œäº†");
        } else {
          console.warn("âš ï¸ ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
        }
      } else {
        console.warn("âš ï¸ ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒã§ã¯ã‚ã‚Šã¾ã›ã‚“ - ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é€£å‹•ã‚¹ã‚­ãƒƒãƒ—");
      }

      // çµ±åˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã§AIå¿œç­”ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’é–‹å§‹
      console.log("ğŸ”Š çµ±åˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚µãƒ¼ãƒ“ã‚¹é–‹å§‹");
      await integratedLipSyncService.startAIResponseLipSync(text);

      // éŸ³å£°åˆæˆã®å®Œäº†ã‚’ç›£è¦–ã™ã‚‹ãŸã‚ã®Promiseã‚’ä½œæˆ
      console.log("ğŸ”Š éŸ³å£°åˆæˆå®Œäº†å¾…æ©Ÿé–‹å§‹");
      await this.waitForSpeechCompletion(text);
      console.log("ğŸ”Š éŸ³å£°åˆæˆå®Œäº†");
    } catch (error) {
      console.error("âŒ AIå¿œç­”éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:", error);
      this.handleError({
        type: "speech-synthesis-failed",
        message: `éŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${error}`,
      });
    }
  }

  /**
   * éŸ³å£°åˆæˆã®å®Œäº†ã‚’å¾…æ©Ÿ
   */
  private waitForSpeechCompletion(text: string): Promise<void> {
    return new Promise((resolve) => {
      console.log(`éŸ³å£°åˆæˆå®Œäº†å¾…æ©Ÿé–‹å§‹: "${text.substring(0, 30)}..."`);

      // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã«åŸºã¥ã„ã¦å‹•çš„ã«è¨­å®šï¼‰
      const estimatedDuration = Math.max(5000, text.length * 150); // æœ€ä½5ç§’ã€æ–‡å­—æ•°Ã—150ms
      console.log(`æ¨å®šéŸ³å£°æ™‚é–“: ${estimatedDuration}ms`);

      const timeout = setTimeout(() => {
        console.warn("âš ï¸ éŸ³å£°åˆæˆã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ - å¼·åˆ¶çš„ã«å®Œäº†ã¨ã¿ãªã—ã¾ã™");
        this.setStatus("idle"); // å¼·åˆ¶çš„ã«ã‚¢ã‚¤ãƒ‰ãƒ«çŠ¶æ…‹ã«æˆ»ã™
        resolve();
      }, estimatedDuration);

      let checkCount = 0;
      const maxChecks = Math.floor(estimatedDuration / 100); // æœ€å¤§ãƒã‚§ãƒƒã‚¯å›æ•°

      // éŸ³å£°åˆæˆã®å®Œäº†ã‚’ç›£è¦–
      const checkCompletion = () => {
        checkCount++;
        const status = integratedLipSyncService.getStatus();
        const isSpeaking = this.speechSynthesis.isSpeaking();

        // è©³ç´°ãƒ­ã‚°ï¼ˆæœ€åˆã®5å›ã¨æœ€å¾Œã®5å›ã€ãã®å¾Œã¯10å›ã«1å›ï¼‰
        if (
          checkCount <= 5 ||
          checkCount >= maxChecks - 5 ||
          checkCount % 10 === 0
        ) {
          console.log(
            `ğŸ” éŸ³å£°çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯[${checkCount}/${maxChecks}]: TTS=${status.isTTSSpeaking}, Speech=${isSpeaking}, Status=${this.status}`
          );
        }

        if (!status.isTTSSpeaking && !isSpeaking) {
          // éŸ³å£°åˆæˆãŒå®Œäº†ã—ãŸ
          clearTimeout(timeout);
          console.log("âœ… éŸ³å£°åˆæˆå®Œäº†ã‚’æ¤œçŸ¥ - ã‚¢ã‚¤ãƒ‰ãƒ«çŠ¶æ…‹ã«ç§»è¡Œ");
          this.setStatus("idle");
          resolve();
        } else if (checkCount >= maxChecks) {
          // æœ€å¤§ãƒã‚§ãƒƒã‚¯å›æ•°ã«é”ã—ãŸ
          clearTimeout(timeout);
          console.warn("âš ï¸ æœ€å¤§ãƒã‚§ãƒƒã‚¯å›æ•°ã«é”ã—ã¾ã—ãŸ - å¼·åˆ¶å®Œäº†");
          this.setStatus("idle");
          resolve();
        } else {
          // ã¾ã è©±ã—ã¦ã„ã‚‹å ´åˆã¯100mså¾Œã«å†ãƒã‚§ãƒƒã‚¯
          setTimeout(checkCompletion, 100);
        }
      };

      // å°‘ã—é…å»¶ã—ã¦ã‹ã‚‰ãƒã‚§ãƒƒã‚¯é–‹å§‹ï¼ˆéŸ³å£°åˆæˆã®é–‹å§‹ã‚’å¾…ã¤ï¼‰
      setTimeout(checkCompletion, 500);
    });
  }

  /**
   * ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´
   */
  private setStatus(newStatus: AudioChatStatus): void {
    if (this.status !== newStatus) {
      const oldStatus = this.status;
      this.status = newStatus;
      console.log(`éŸ³å£°ãƒãƒ£ãƒƒãƒˆçŠ¶æ…‹å¤‰æ›´: ${oldStatus} â†’ ${newStatus}`);
      this.callbacks.onStatusChange?.(newStatus);
    }
  }

  /**
   * ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
   */
  private handleError(error: AudioError): void {
    this.setStatus("error");
    this.callbacks.onError?.(error);
    console.error("AudioChatIntegration ã‚¨ãƒ©ãƒ¼:", error);
  }

  /**
   * è¨­å®šæ›´æ–°
   */
  public updateConfig(newConfig: Partial<AudioChatConfig>): void {
    this.config = { ...this.config, ...newConfig };

    // å„ã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®šã‚‚æ›´æ–°
    if (newConfig.speechRecognition) {
      this.speechRecognition.updateConfig({
        language: newConfig.speechRecognition.language,
        continuous: newConfig.speechRecognition.continuous,
        interimResults: newConfig.speechRecognition.interimResults,
        maxAlternatives: 1,
      });
    }
    if (newConfig.speechSynthesis) {
      this.speechSynthesis.updateConfig({
        voice: newConfig.speechSynthesis.voice,
        rate: newConfig.speechSynthesis.rate,
        pitch: newConfig.speechSynthesis.pitch,
        volume: newConfig.speechSynthesis.volume,
        language: this.config.speechRecognition.language,
      });
    }
  }

  /**
   * ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—
   */
  public getStatus(): AudioChatStatus {
    return this.status;
  }

  /**
   * ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ç¢ºèª
   */
  public isAudioChatActive(): boolean {
    return this.isActive;
  }

  /**
   * åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ä¸€è¦§å–å¾—
   */
  public getAvailableVoices(): SpeechSynthesisVoice[] {
    return this.speechSynthesis.getAvailableVoices();
  }

  /**
   * æ—¥æœ¬èªéŸ³å£°ä¸€è¦§å–å¾—
   */
  public getJapaneseVoices(): SpeechSynthesisVoice[] {
    return this.speechSynthesis.getJapaneseVoices();
  }

  /**
   * ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
   */
  public cleanup(): void {
    this.stopAudioChat();
    this.audioInput.cleanup();
    this.speechRecognition.cleanup();
    this.speechSynthesis.cleanup();
  }
}
