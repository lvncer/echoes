# Echoes 要件定義書

## 1. プロジェクト概要

### 1.1. プロジェクト名

**Echoes（エコーズ）**

### 1.2. プロジェクトの目的・背景

- **目的**: ユーザーが持ち込んだ 3D モデル（アバター）と、AI を介してリアルタイムに音声で会話できるアプリケーションの開発
- **背景**: AI 技術の普及により、よりインタラクティブで親しみやすい AI 体験の需要が高まっている
- **ターゲットユーザー**:
  - VTuber・配信者
  - AI 技術に興味のある一般ユーザー
  - 3D モデル愛好家

### 1.3. プロジェクトスコープ

- **対象プラットフォーム**: Web → デスクトップ → モバイル（段階的展開）
- **開発期間**: 約 7-9 ヶ月
- **開発チーム規模**: 1-3 名想定

## 2. 機能要件

### 2.1. 機能一覧

```mermaid
graph LR
    A["Echoes"] --> B["3Dモデル管理"]
    A --> C["音声処理"]
    A --> D["AI連携"]
    A --> E["アニメーション"]
    A --> F["UI/設定"]

    B --> B1["モデル読み込み"]
    B --> B2["モデル表示"]
    B --> B3["モデル保存・切り替え"]

    C --> C1["音声入力・認識"]
    C --> C2["音声合成・出力"]
    C --> C3["音声制御"]

    D --> D1["AI応答生成"]
    D --> D2["キャラクター設定"]
    D --> D3["複数プロバイダー対応"]

    E --> E1["リップシンク"]
    E --> E2["表情・ジェスチャー"]
    E --> E3["アニメーション制御"]

    F --> F1["会話インターフェース"]
    F --> F2["設定画面"]
    F --> F3["データ管理"]
```

### 2.2. 詳細機能仕様

#### 2.2.1. 3D モデル管理機能

| 機能 ID | 機能名                 | 詳細                    | 優先度 |
| ------- | ---------------------- | ----------------------- | ------ |
| F1      | モデルファイル読み込み | VRM、glTF、FBX 形式対応 | 高     |
| F2      | モデル表示・操作       | 3D 表示、カメラ操作     | 高     |
| F2-1    | モデル保存・管理       | 複数モデル切り替え      | 中     |

#### 2.2.2. 音声処理機能

| 機能 ID | 機能名        | 詳細                         | 優先度 |
| ------- | ------------- | ---------------------------- | ------ |
| F3      | マイク入力    | デバイス選択、入力レベル表示 | 高     |
| F4      | 音声認識(STT) | リアルタイム日本語認識       | 高     |
| F4-1    | 音声入力制御  | プッシュトゥトーク、VAD      | 中     |
| F6      | 音声合成(TTS) | 日本語対応、声質選択         | 高     |
| F7      | 音声再生      | 基本再生機能                 | 高     |
| F7-1    | 音声出力制御  | 速度・音量調整、一時停止     | 低     |

#### 2.2.3. AI 連携機能

| 機能 ID | 機能名              | 詳細                               | 優先度 |
| ------- | ------------------- | ---------------------------------- | ------ |
| F5      | AI 応答生成         | LLM 連携、応答生成                 | 高     |
| F5-1    | AI 設定カスタマイズ | キャラクター設定、プロバイダー選択 | 中     |

#### 2.2.4. アニメーション機能

| 機能 ID | 機能名             | 詳細                   | 優先度 |
| ------- | ------------------ | ---------------------- | ------ |
| F8      | リップシンク       | 音声同期口パク         | 高     |
| F9      | 表情・ジェスチャー | 感情表現アニメーション | 低     |
| F9-1    | アニメーション制御 | 強度調整、ON/OFF       | 低     |

#### 2.2.5. UI・設定機能

| 機能 ID | 機能名               | 詳細                       | 優先度 |
| ------- | -------------------- | -------------------------- | ------ |
| F10     | 会話インターフェース | チャット画面、会話ログ     | 高     |
| F11     | 設定画面             | 各種設定管理               | 中     |
| F11-1   | データ管理           | 履歴保存、設定エクスポート | 低     |

#### 2.2.6. セキュリティ・システム機能

| 機能 ID | 機能名             | 詳細                     | 優先度 |
| ------- | ------------------ | ------------------------ | ------ |
| F12     | データ保護         | 暗号化、プライバシー保護 | 中     |
| F13     | エラーハンドリング | 例外処理、自動復旧       | 中     |
| F14     | ログ機能           | デバッグログ、問題報告   | 低     |

## 3. 非機能要件

### 3.1. パフォーマンス要件

| 項目           | 要件                                   | 測定方法           |
| -------------- | -------------------------------------- | ------------------ |
| 応答時間       | 音声認識 →AI 応答 → 音声合成: 3 秒以内 | 実測               |
| フレームレート | 3D レンダリング: 30fps 以上            | パフォーマンス監視 |
| メモリ使用量   | 最大 2GB 以内                          | リソース監視       |

### 3.2. 可用性・信頼性要件

| 項目         | 要件                                |
| ------------ | ----------------------------------- |
| 稼働率       | 99%以上（ネットワーク依存部分除く） |
| 障害復旧時間 | 自動復旧: 30 秒以内                 |
| データ保護   | ローカルデータの暗号化保存          |

### 3.3. 互換性要件

| 項目               | 要件                                  |
| ------------------ | ------------------------------------- |
| ブラウザ           | Chrome 90+, Firefox 88+, Safari 14+   |
| OS（デスクトップ） | Windows 10+, macOS 11+, Ubuntu 20.04+ |
| OS（モバイル）     | iOS 14+, Android 10+                  |

## 4. システム構成・アーキテクチャ

### 4.1. システム全体構成

```mermaid
graph TB
    subgraph "フロントエンド"
        A["Next.js Web App"]
        B["Electron Desktop"]
        C["React Native Mobile"]
    end

    subgraph "外部サービス"
        D["OpenAI API"]
        E["Google Cloud Speech"]
        F["VOICEVOX API"]
    end

    subgraph "ローカルストレージ"
        G["設定データ"]
        H["会話履歴"]
        I["3Dモデルファイル"]
    end

    A --> D
    A --> E
    A --> F
    A --> G
    A --> H
    A --> I

    B --> A
    C -.-> A
```

### 4.2. アプリケーション構成

```mermaid
graph TB
    subgraph "プレゼンテーション層"
        A["React Components"]
        B["Three.js Canvas"]
        C["Audio Controls"]
    end

    subgraph "ビジネスロジック層"
        D["State Management<br/>(Zustand)"]
        E["Audio Processing"]
        F["3D Model Controller"]
        G["AI Service"]
    end

    subgraph "データアクセス層"
        H["Local Storage API"]
        I["External API Client"]
        J["File System API"]
    end

    A --> D
    B --> F
    C --> E
    D --> G
    E --> I
    F --> J
    G --> I
    H --> D
```

### 4.3. データフロー

```mermaid
sequenceDiagram
    participant U as ユーザー
    participant UI as UI層
    participant AL as オーディオ層
    participant AI as AI層
    participant M as 3Dモデル層

    U->>UI: 音声入力開始
    UI->>AL: 録音開始
    AL->>AL: 音声認識(STT)
    AL->>UI: テキスト表示
    UI->>AI: AI応答リクエスト
    AI->>AI: 応答生成
    AI->>UI: 応答テキスト
    UI->>AL: 音声合成(TTS)
    AL->>M: リップシンク開始
    AL->>U: 音声再生
    M->>U: アニメーション表示
```

## 5. 技術仕様

### 5.1. 開発技術スタック

| 層              | 技術                         | 理由                               |
| --------------- | ---------------------------- | ---------------------------------- |
| フロントエンド  | Next.js + TypeScript         | React 生態系、型安全性             |
| 3D レンダリング | Three.js + React Three Fiber | Web 標準、React 統合               |
| 状態管理        | Zustand                      | 軽量、シンプル                     |
| スタイリング    | Tailwind CSS                 | 高速開発、一貫性                   |
| デスクトップ化  | Electron/Tauri               | Web 技術活用                       |
| モバイル        | React Native + Expo          | コード共有、クロスプラットフォーム |

### 5.2. 外部サービス・API

| サービス       | 用途        | 代替案                              |
| -------------- | ----------- | ----------------------------------- |
| OpenAI API     | AI 応答生成 | Anthropic Claude, ローカル LLM      |
| OpenAI Whisper | 音声認識    | Google Cloud Speech, Web Speech API |
| OpenAI TTS     | 音声合成    | Google Cloud TTS, VOICEVOX          |

### 5.3. AI 実装アプローチ

#### 段階的実装戦略

```mermaid
graph LR
    A["Phase 1<br/>.env設定"] --> B["Phase 2<br/>Web UI設定"]
    B --> C["Phase 3<br/>ローカルLLM対応"]

    A1["OpenAI API<br/>基本実装"] --> A
    B1["プロバイダー<br/>切り替え機能"] --> B
    C1["Ollama等<br/>ローカル対応"] --> C
```

#### AI プロバイダー設定構造

```typescript
interface AIProviderConfig {
  provider: "openai" | "anthropic" | "local";
  apiKey?: string;
  baseUrl?: string;
  model: string;
  maxTokens?: number;
  temperature?: number;
}

interface AISettings {
  currentProvider: AIProviderConfig;
  providers: {
    openai: AIProviderConfig;
    anthropic: AIProviderConfig;
    local: AIProviderConfig;
  };
}
```

#### 実装優先順位

| フェーズ | 機能                     | 優先度 | 実装方法           |
| -------- | ------------------------ | ------ | ------------------ |
| Phase 1  | OpenAI API 基本実装      | 高     | .env 設定          |
| Phase 2  | Web UI 設定画面          | 中     | 設定コンポーネント |
| Phase 3  | ローカル LLM 対応        | 低     | Ollama 連携        |
| Phase 4  | 複数プロバイダー同時対応 | 低     | 拡張アーキテクチャ |

## 6. 開発計画

### 6.1. 開発フェーズ

```mermaid
gantt
    title Echoes 開発スケジュール
    dateFormat  YYYY-MM-DD
    section フェーズ1: Web版MVP
    要件定義・設計     :done, req, 2024-01-01, 2024-01-15
    基本UI構築        :active, ui, 2024-01-16, 2024-02-15
    3Dモデル表示      :model, 2024-02-01, 2024-02-28
    音声処理基盤      :audio, 2024-02-15, 2024-03-15
    AI連携           :ai, 2024-03-01, 2024-03-31
    リップシンク      :lip, 2024-03-15, 2024-04-15

    section フェーズ2: Web版完成
    高度機能実装      :advanced, 2024-04-16, 2024-05-31
    テスト・最適化    :test, 2024-05-15, 2024-06-15

    section フェーズ3: デスクトップ版
    Electron統合     :desktop, 2024-06-16, 2024-07-15

    section フェーズ4: モバイル版
    React Native実装 :mobile, 2024-07-16, 2024-09-30
```

### 6.2. マイルストーン

| フェーズ   | 期間     | 主要成果物     | 成功基準               |
| ---------- | -------- | -------------- | ---------------------- |
| フェーズ 1 | 2-3 ヶ月 | Web 版 MVP     | 基本的な会話機能が動作 |
| フェーズ 2 | 1-2 ヶ月 | Web 版完成     | 全機能実装・テスト完了 |
| フェーズ 3 | 1 ヶ月   | デスクトップ版 | Electron での動作確認  |
| フェーズ 4 | 2-3 ヶ月 | モバイル版     | iOS/Android 対応完了   |

## 7. リスク管理

### 7.1. 技術リスク

| リスク                            | 影響度 | 発生確率 | 対策                              |
| --------------------------------- | ------ | -------- | --------------------------------- |
| Three.js でのリップシンク実装困難 | 高     | 中       | 事前 PoC 実施、代替手法検討       |
| Web Speech API の制限             | 中     | 高       | 外部 API 併用、フォールバック実装 |
| モバイル版での 3D 性能問題        | 中     | 中       | 軽量化、LOD 実装                  |

### 7.2. プロジェクトリスク

| リスク              | 影響度 | 発生確率 | 対策                       |
| ------------------- | ------ | -------- | -------------------------- |
| 開発期間の延長      | 中     | 中       | MVP 優先、段階的リリース   |
| 外部 API 費用の増大 | 低     | 低       | 使用量監視、ローカル代替案 |

## 8. 品質保証

### 8.1. テスト戦略

- **単体テスト**: Vitest + Testing Library
- **統合テスト**: Playwright
- **パフォーマンステスト**: Lighthouse, Web Vitals
- **ユーザビリティテスト**: 実ユーザーによる評価

### 8.2. 品質基準

- **コードカバレッジ**: 80%以上
- **パフォーマンススコア**: Lighthouse 90 点以上
- **アクセシビリティ**: WCAG 2.1 AA 準拠

## 9. 次のステップ・実装計画

### 9.1. 現在の実装状況

#### ✅ 完了済み機能

- **3D モデル表示機能**: VRM/glTF/GLB 対応、ドラッグ&ドロップ、カメラ操作
- **AI チャット機能**: OpenAI/Gemini API 対応、プロバイダー切り替え
- **基本 UI**: レスポンシブデザイン、タブ切り替え
- **音声処理基盤**: 音声入力・録音、音声認識(STT)、音声合成(TTS)、プッシュトゥトーク制御

#### 🔄 次の優先実装項目

**SSoT（Single Source of Truth）原則に基づき、詳細な実装計画は GitHub Issue で管理しています。**

##### ✅ Phase 1: コード品質向上・リファクタリング（完了）

- デバッグコード削除、テストコード実装、コード最適化、エラーハンドリング強化

##### ✅ Phase 2: 音声処理基盤（完了）

- 音声入力・録音機能: MediaRecorder API、音声レベル監視
- 音声認識(STT): Web Speech API 統合、リアルタイム認識
- 音声合成(TTS): Web Speech API 統合、音声設定制御
- 音声制御: プッシュトゥトーク、音声チャット統合サービス

##### ✅ Phase 3: リップシンク・アニメーション（完了）

**詳細**: [GitHub Issue #13 - Phase 3: リップシンク・アニメーション実装](https://github.com/lvncer/echoes/issues/13)

**Phase 3-1: VRM ブレンドシェイプ基盤** ✅

- ✅ VRM ブレンドシェイプアクセス機能の実装
- ✅ ブレンドシェイプ制御サービスの作成
- ✅ 基本的な表情制御のテスト
- ✅ ブレンドシェイプテスト・デモ機能

**Phase 3-2: 音素解析・リップシンク** ✅

- ✅ 音声データから音素抽出機能
- ✅ 15 音素対応（sil, aa, ih, ou, E, oh, PP, FF, TH, DD, kk, CH, SS, nn, RR）
- ✅ リアルタイム音素解析とブレンドシェイプ制御
- ✅ 基本・高精度リップシンクサービス

**Phase 3-3: アニメーション統合** ✅

- ✅ 音声処理サービスとの統合
- ✅ AI 応答連動アニメーション
- ✅ 感情表現・ジェスチャー制御
- ✅ TTS 音声連動リップシンク
- ✅ 統合デバッグパネル

##### 🚀 Phase 4: 高度機能・最適化（次の実装対象）

**Phase 4-1: UI/UX 改善**

- 設定画面 UI: カメラ・ライティング・アニメーション詳細設定
- リップシンク設定パネル: 感度・応答性・音素マッピング調整
- 3D ビューアー操作性向上: カメラプリセット、ライティング調整

**Phase 4-2: データ管理・永続化**

- 会話履歴保存・検索機能
- ユーザー設定エクスポート・インポート
- VRM モデル管理・お気に入り機能

**Phase 4-3: パフォーマンス最適化**

- LOD（Level of Detail）システム
- ブレンドシェイプキャッシュ・圧縮
- リップシンク処理の最適化
- メモリ使用量削減

##### 📋 Phase 5: 音声処理拡張（予定）

- OpenAI Whisper/TTS API 統合
- VOICEVOX 統合
- 高品質音声処理オプション
- 多言語音声認識・合成対応

### 9.2. 技術的課題と対策

#### リップシンク実装の技術選択

**Phase 3 実装アプローチ**

| 機能                 | 採用技術                       | 理由                           |
| -------------------- | ------------------------------ | ------------------------------ |
| ブレンドシェイプ制御 | @pixiv/three-vrm API           | VRM 標準、Three.js 統合        |
| 音素解析             | Web Audio API + 音素マッピング | ブラウザ標準、リアルタイム処理 |
| リップシンク制御     | カスタム実装                   | 柔軟性、パフォーマンス最適化   |

**VRM ブレンドシェイプ対応音素**

| 音素分類 | 音素                   | 対応する口の形    | 実装優先度 |
| -------- | ---------------------- | ----------------- | ---------- |
| 基本母音 | sil, aa, ih, ou, E, oh | あいうえお + 無音 | 高         |
| 子音     | PP, FF, TH, DD, kk     | 唇・歯音          | 中         |
| 子音     | CH, SS, nn, RR         | 舌音・鼻音        | 中         |

#### パフォーマンス目標（更新）

- **音声認識 →AI 応答 → 音声合成**: 3 秒以内
- **リップシンク応答性**: 100ms 以内
- **3D レンダリング**: 30fps 以上維持（リップシンク含む）
- **メモリ使用量**: 2GB 以内
- **バンドルサイズ**: 600KB 以内（リップシンク機能追加後）

### 9.3. 開発ロードマップ更新

```mermaid
gantt
    title Echoes 開発ロードマップ（更新版）
    dateFormat  YYYY-MM-DD
    section 完了済み
    3Dモデル表示機能    :done, 3d, 2025-06-01, 2025-06-11
    AIチャット機能      :done, ai, 2025-06-01, 2025-06-11
    リファクタリング    :done, refactor, 2025-06-11, 2025-06-18
    テストコード実装    :done, test, 2025-06-15, 2025-06-25
    音声処理基盤        :done, audio, 2025-06-25, 2025-07-20

    section Phase 3: リップシンク・アニメーション
    VRMブレンドシェイプ基盤  :active, blend, 2025-07-20, 2025-08-05
    音素解析・リップシンク   :lipsync, 2025-08-01, 2025-08-20
    アニメーション統合      :animation, 2025-08-15, 2025-09-05

    section Phase 4: 高度機能
    設定画面UI          :settings, 2025-08-25, 2025-09-15
    データ管理          :data, 2025-09-01, 2025-09-20

    section Phase 5: 音声処理拡張
    OpenAI Whisper/TTS  :openai-audio, 2025-09-10, 2025-09-30
    VOICEVOX統合        :voicevox, 2025-09-20, 2025-10-10
```

### 9.4. 品質保証計画

#### テスト実装計画（更新）

1. **単体テスト**: 各コンポーネント・サービスの個別テスト
2. **統合テスト**: 3D 表示・AI 連携・音声処理・リップシンクの統合動作テスト
3. **E2E テスト**: ユーザーシナリオベースの完全動作テスト
4. **パフォーマンステスト**: 負荷テスト・メモリリークテスト・リップシンク応答性テスト

#### コード品質基準

- **TypeScript 厳格モード**: strict: true
- **ESLint**: エラー 0、警告最小化
- **Prettier**: コードフォーマット統一
- **コードカバレッジ**: 80%以上

### 9.5. 実装前の確認事項

#### ✅ 確認完了項目

**1. VRM モデル仕様**

- ✅ テスト用 VRM モデル: ニコニ立体ちゃん（ユーザー提供）
- ✅ 基本 5 音素から開始、段階的に 15 音素まで拡張
- ✅ ブレンドシェイプ対応状況: 標準的な VRM ブレンドシェイプ想定

**2. パフォーマンス要件**

- ✅ リップシンク遅延: 250ms 程度（許容済み）
- ✅ フレームレート目標: 30fps 以上維持
- ✅ パフォーマンス重視アプローチ採用

**3. 実装アプローチ**

- ✅ 段階的実装: 音量ベース → 音素解析（承認済み）
- ✅ 音素マッピング方式: 5 音素 → 15 音素
- ✅ Web Audio API 使用、Web Worker 活用

#### ✅ Phase 3 実装完了

**実装済み機能**

- VRM ブレンドシェイプ制御: `@pixiv/three-vrm` API
- 音素解析: Web Audio API `AnalyserNode`
- 基本・高精度・統合リップシンクサービス
- TTS 音声連動リップシンク
- 感情表現・アニメーション制御
- 統合デバッグパネル

## 10. リップシンク機能使用ガイド

### 10.1. 基本的な使用手順

#### ステップ 1: VRM モデルの準備と読み込み

1. **対応モデル形式**: VRM、glTF、GLB
2. **推奨モデル**: ブレンドシェイプ対応の VRM モデル
3. **読み込み方法**: 中央の 3D ビューアーエリアにドラッグ&ドロップ

```markdown
✅ 読み込み成功の確認方法

- モデルが 3D ビューアーに表示される
- デバッグパネルで「VRM モデル: ✓」が表示される
- ブレンドシェイプ数が 0 以上で表示される
```

#### ステップ 2: リップシンクモードの選択

**左側「リップシンク制御」パネルから選択**

| モード                 | 用途               | 特徴              | 推奨シーン           |
| ---------------------- | ------------------ | ----------------- | -------------------- |
| **基本リップシンク**   | 簡単な口パク       | 音量ベース制御    | リアルタイム会話     |
| **高精度リップシンク** | 自然なリップシンク | 15 音素解析       | 高品質アニメーション |
| **統合リップシンク**   | AI 連動自動制御    | TTS 同期+感情表現 | AI 音声チャット      |

#### ステップ 3: 音声チャットでの使用

1. **右側「音声」タブを選択**
2. **「リップシンク連動」ボタン（😊）を ON**
3. **「録音開始」でマイク入力開始**
4. **AI 応答時に自動リップシンク実行**

### 10.2. 各モードの詳細設定

#### 基本リップシンクモード

**制御パラメータ**

- **感度**: 0.1-3.0（音量に対する反応の強さ）
- **応答性**: 0.1-1.0（アニメーションの滑らかさ）
- **音量閾値**: 0.001-0.1（反応開始の音量レベル）

**使用方法**

1. 左側パネルの「基本リップシンク」で「開始」をクリック
2. マイクアクセスを許可
3. 話すと音量に応じて口が開閉

#### 高精度リップシンクモード

**対応音素（15 種類）**

- **母音**: sil（無音）、aa（あ）、ih（い）、ou（う）、E（え）、oh（お）
- **子音**: PP（p/b）、FF（f/v）、TH（th）、DD（d/t）、kk（k/g）、CH（ch/j）、SS（s/z）、nn（n/m）、RR（r/l）

**使用方法**

1. 左側パネルの「高精度リップシンク」で「開始」をクリック
2. フォルマント解析による高精度な口の形制御
3. 音素履歴と信頼度をリアルタイム表示

#### 統合リップシンクモード

**自動連動機能**

- **AI 応答連動**: ON/OFF 切り替え
- **感情表現**: 5 種類（neutral, happy, sad, angry, surprised）
- **感情強度**: 0.0-1.0 で調整可能

**使用方法**

1. 左側パネルの「統合リップシンク」でマイクを「開始」
2. 「AI 応答連動」を ON に設定
3. 右側「音声」タブで音声チャット開始
4. AI 応答時に自動でリップシンク+感情表現

### 10.3. デバッグ・トラブルシューティング

#### デバッグパネルの使用方法

**右下「デバッグ」ボタンから確認可能な情報**

```
システム状態
├── Web Audio API: ✓/✗
├── VRMモデル: ✓/✗
└── マイクアクセス: ✓/✗

アクティブサービス
├── 基本リップシンク: ON/OFF
├── 高精度リップシンク: ON/OFF
└── 統合リップシンク: ON/OFF

詳細情報
├── 現在の音素: [リアルタイム表示]
├── 口の開き: [0-100%]
└── ブレンドシェイプ数: [利用可能数]
```

#### よくある問題と解決方法

**1. マイクアクセスエラー**

```
エラー: マイクロフォンへのアクセスが拒否されました
```

**解決方法**:

- ブラウザのアドレスバー左側のマイクアイコンをクリック
- 「許可」を選択してページを再読み込み

**2. VRM モデルが反応しない**

```
警告: ブレンドシェイプが利用できません
```

**解決方法**:

- VRM モデルにブレンドシェイプが含まれているか確認
- デバッグパネルで「統合テスト実行」を試行
- 別の VRM モデルで動作確認

**3. リップシンクの遅延**

```
症状: 音声とリップシンクがずれる
```

**解決方法**:

- 基本モードから試して段階的に高精度モードに移行
- ブラウザのハードウェアアクセラレーションを有効化
- 他のタブやアプリケーションを閉じてリソースを確保

**4. 音素認識の精度が低い**

```
症状: 高精度モードで正しい口の形にならない
```

**解決方法**:

- マイクの音質を確認（ノイズキャンセリング推奨）
- 統合リップシンクの感度設定を調整
- 明瞭な発音を心がける

### 10.4. パフォーマンス最適化

#### 推奨環境設定

**ブラウザ設定**

- Chrome 90+ / Firefox 88+ / Safari 14+
- ハードウェアアクセラレーション: 有効
- マイクアクセス: 許可

**システム要件**

- CPU: 2GHz 以上のマルチコア
- メモリ: 4GB 以上
- GPU: WebGL 対応

#### パフォーマンス監視

**デバッグパネルで確認可能な指標**

- フレームレート: 30fps 以上を維持
- メモリ使用量: 2GB 以内
- 音声遅延: 100ms 以内
- リップシンク遅延: 250ms 以内

### 10.5. 高度な使用方法

#### カスタム感情表現

**統合リップシンクモードでの感情テスト**

1. 左側「統合リップシンク」パネルの「感情テスト」セクション
2. 5 種類の感情ボタンから選択
3. 各感情に対応したテストテキストで動作確認

**感情マッピング**

- **neutral**: 通常の表情
- **happy**: 笑顔、明るい表情
- **sad**: 悲しい表情、口角下がり
- **angry**: 怒り、眉間にしわ
- **surprised**: 驚き、目と口を大きく開く

#### 複数モードの併用

**推奨使用パターン**

1. **開発・テスト時**: 基本 → 高精度 → 統合の順で動作確認
2. **リアルタイム配信**: 統合リップシンクで AI 応答連動
3. **デモンストレーション**: 高精度リップシンクで自然なアニメーション

**テスト手順**

1. **VRM モデル読み込み**: 3D ビューアーでモデルをドラッグ&ドロップ
2. **ブレンドシェイプテスト**: デバッグパネル → 統合テスト実行
3. **基本リップシンク**: 左側パネルでマイク入力リップシンク
4. **高精度リップシンク**: 音素解析による 15 音素対応リップシンク
5. **音声チャット連動**: 音声タブで AI 応答時の自動リップシンク
6. **デバッグ監視**: 右下デバッグパネルでシステム状態確認

**パフォーマンス目標達成状況**

- ✅ リップシンク応答性: 100ms 以内
- ✅ 3D レンダリング: 30fps 以上維持
- ✅ 音声認識 →AI 応答 → 音声合成: 3 秒以内
- ✅ メモリ使用量: 2GB 以内
- リップシンク制御: カスタム実装

**テスト環境確定**

- テスト用 VRM モデル: ニコニ立体ちゃん（ユーザー提供）
- 開発環境: 現在のプロジェクト環境
- 追加ライブラリ: 最小限に抑制
